{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "774365d7-2145-4709-9682-9c58acb32ac8",
   "metadata": {},
   "source": [
    "# Question 4: Adversarial Search for Traveling Ethiopia Coffee Problem\n",
    "## 4.1 MiniMax Search Algorithm Implementation\n",
    "### Game State Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2900a679-a509-4c24-89de-23112b1371f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c26cec1-9244-4ab2-abdd-f7e555500fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3bdc105-528a-49ea-aa27-77ffd369180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CoffeeAdversaryGame:\n",
    "    \"\"\"Represents the adversarial traveling Ethiopia coffee search problem\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Game tree based on Figure 4 with utility values (coffee quality scores)\n",
    "        # Higher utility = better coffee quality\n",
    "        \n",
    "        # Map of locations and their coffee quality (terminal nodes have utility values)\n",
    "        self.coffee_quality = {\n",
    "            # Terminal nodes with utility values (coffee quality scores)\n",
    "            'Gemba': 8,      # Good quality coffee\n",
    "            'Limu': 7,       # Moderate quality\n",
    "            'Hossana': 9,    # Excellent quality\n",
    "            'Duma': 6,       # Fair quality\n",
    "            'Bekembe': 5,    # Average quality\n",
    "            'Buta Jirra': 7, # Moderate quality\n",
    "            'Worabe': 6,     # Fair quality\n",
    "            'Wolkite': 8,    # Good quality\n",
    "            'Mojo': 4,       # Below average\n",
    "            'Addis Ababa': 3, # Basic quality\n",
    "            'Adama': 5,      # Average quality\n",
    "            'Diredaw': 6,    # Fair quality\n",
    "            'Harar': 10,     # Premium quality (famous Harar coffee)\n",
    "            'Dilla': 9,      # Excellent quality\n",
    "            'Kaffa': 10,     # Premium quality (birthplace of coffee)\n",
    "            'Chiliro': 7,    # Moderate quality\n",
    "            'Dede': 6,       # Fair quality\n",
    "            'Ambo': 5,       # Average quality\n",
    "            'Fincha': 4,     # Below average\n",
    "            'Shambu': 7      # Moderate quality\n",
    "        }\n",
    "        \n",
    "        # Game tree structure (who moves from each state)\n",
    "        # MAX = Agent (wants high coffee quality)\n",
    "        # MIN = Adversary (wants low coffee quality)\n",
    "        \n",
    "        self.game_tree = {\n",
    "            # Level 1: MAX's turn (Agent starts from initial positions)\n",
    "            'start': {\n",
    "                'type': 'MAX',\n",
    "                'children': ['region_north', 'region_south', 'region_east']\n",
    "            },\n",
    "            \n",
    "            # Level 2: MIN's turn (Adversary responds)\n",
    "            'region_north': {\n",
    "                'type': 'MIN',\n",
    "                'children': ['north_option1', 'north_option2']\n",
    "            },\n",
    "            'region_south': {\n",
    "                'type': 'MIN',\n",
    "                'children': ['south_option1', 'south_option2', 'south_option3']\n",
    "            },\n",
    "            'region_east': {\n",
    "                'type': 'MIN',\n",
    "                'children': ['east_option1', 'east_option2']\n",
    "            },\n",
    "            \n",
    "            # Level 3: MAX's turn again (Agent chooses specific coffee regions)\n",
    "            'north_option1': {\n",
    "                'type': 'MAX',\n",
    "                'children': ['Gemba', 'Limu', 'Fincha']\n",
    "            },\n",
    "            'north_option2': {\n",
    "                'type': 'MAX',\n",
    "                'children': ['Shambu', 'Ambo', 'Dede']\n",
    "            },\n",
    "            'south_option1': {\n",
    "                'type': 'MAX',\n",
    "                'children': ['Hossana', 'Duma', 'Worabe']\n",
    "            },\n",
    "            'south_option2': {\n",
    "                'type': 'MAX',\n",
    "                'children': ['Wolkite', 'Buta Jirra', 'Bekembe']\n",
    "            },\n",
    "            'south_option3': {\n",
    "                'type': 'MAX',\n",
    "                'children': ['Dilla', 'Kaffa', 'Chiliro']\n",
    "            },\n",
    "            'east_option1': {\n",
    "                'type': 'MAX',\n",
    "                'children': ['Addis Ababa', 'Adama', 'Mojo']\n",
    "            },\n",
    "            'east_option2': {\n",
    "                'type': 'MAX',\n",
    "                'children': ['Diredaw', 'Harar']\n",
    "            },\n",
    "            \n",
    "            # Terminal nodes (actual coffee locations)\n",
    "            'Gemba': {'type': 'TERMINAL', 'utility': 8},\n",
    "            'Limu': {'type': 'TERMINAL', 'utility': 7},\n",
    "            'Fincha': {'type': 'TERMINAL', 'utility': 4},\n",
    "            'Shambu': {'type': 'TERMINAL', 'utility': 7},\n",
    "            'Ambo': {'type': 'TERMINAL', 'utility': 5},\n",
    "            'Dede': {'type': 'TERMINAL', 'utility': 6},\n",
    "            'Hossana': {'type': 'TERMINAL', 'utility': 9},\n",
    "            'Duma': {'type': 'TERMINAL', 'utility': 6},\n",
    "            'Worabe': {'type': 'TERMINAL', 'utility': 6},\n",
    "            'Wolkite': {'type': 'TERMINAL', 'utility': 8},\n",
    "            'Buta Jirra': {'type': 'TERMINAL', 'utility': 7},\n",
    "            'Bekembe': {'type': 'TERMINAL', 'utility': 5},\n",
    "            'Dilla': {'type': 'TERMINAL', 'utility': 9},\n",
    "            'Kaffa': {'type': 'TERMINAL', 'utility': 10},\n",
    "            'Chiliro': {'type': 'TERMINAL', 'utility': 7},\n",
    "            'Addis Ababa': {'type': 'TERMINAL', 'utility': 3},\n",
    "            'Adama': {'type': 'TERMINAL', 'utility': 5},\n",
    "            'Mojo': {'type': 'TERMINAL', 'utility': 4},\n",
    "            'Diredaw': {'type': 'TERMINAL', 'utility': 6},\n",
    "            'Harar': {'type': 'TERMINAL', 'utility': 10}\n",
    "        }\n",
    "        \n",
    "        # Alternative: Simplified game tree as adjacency list\n",
    "        self.adjacency_tree = {\n",
    "            'start': ['region_north', 'region_south', 'region_east'],\n",
    "            'region_north': ['north_option1', 'north_option2'],\n",
    "            'region_south': ['south_option1', 'south_option2', 'south_option3'],\n",
    "            'region_east': ['east_option1', 'east_option2'],\n",
    "            'north_option1': ['Gemba', 'Limu', 'Fincha'],\n",
    "            'north_option2': ['Shambu', 'Ambo', 'Dede'],\n",
    "            'south_option1': ['Hossana', 'Duma', 'Worabe'],\n",
    "            'south_option2': ['Wolkite', 'Buta Jirra', 'Bekembe'],\n",
    "            'south_option3': ['Dilla', 'Kaffa', 'Chiliro'],\n",
    "            'east_option1': ['Addis Ababa', 'Adama', 'Mojo'],\n",
    "            'east_option2': ['Diredaw', 'Harar']\n",
    "        }\n",
    "        \n",
    "        # Player types for each node\n",
    "        self.player_type = {\n",
    "            'start': 'MAX',\n",
    "            'region_north': 'MIN',\n",
    "            'region_south': 'MIN',\n",
    "            'region_east': 'MIN',\n",
    "            'north_option1': 'MAX',\n",
    "            'north_option2': 'MAX',\n",
    "            'south_option1': 'MAX',\n",
    "            'south_option2': 'MAX',\n",
    "            'south_option3': 'MAX',\n",
    "            'east_option1': 'MAX',\n",
    "            'east_option2': 'MAX'\n",
    "        }\n",
    "        \n",
    "        # Terminal node utilities\n",
    "        self.terminal_utilities = self.coffee_quality\n",
    "    \n",
    "    def is_terminal(self, state: str) -> bool:\n",
    "        \"\"\"Check if a state is terminal\"\"\"\n",
    "        return state in self.terminal_utilities\n",
    "    \n",
    "    def get_utility(self, state: str) -> int:\n",
    "        \"\"\"Get utility value for terminal state\"\"\"\n",
    "        return self.terminal_utilities.get(state, 0)\n",
    "    \n",
    "    def get_children(self, state: str) -> List[str]:\n",
    "        \"\"\"Get children states from current state\"\"\"\n",
    "        return self.adjacency_tree.get(state, [])\n",
    "    \n",
    "    def get_player(self, state: str) -> str:\n",
    "        \"\"\"Get player type for current state (MAX or MIN)\"\"\"\n",
    "        return self.player_type.get(state, 'TERMINAL')\n",
    "    \n",
    "    def display_game_tree(self):\n",
    "        \"\"\"Display the game tree structure\"\"\"\n",
    "        print(\"=== COFFEE ADVERSARY GAME TREE ===\")\n",
    "        print(\"\\nGame Structure:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        print(\"Level 1 (MAX - Agent chooses region):\")\n",
    "        print(\"  start → [region_north, region_south, region_east]\")\n",
    "        \n",
    "        print(\"\\nLevel 2 (MIN - Adversary chooses sub-region):\")\n",
    "        print(\"  region_north → [north_option1, north_option2]\")\n",
    "        print(\"  region_south → [south_option1, south_option2, south_option3]\")\n",
    "        print(\"  region_east → [east_option1, east_option2]\")\n",
    "        \n",
    "        print(\"\\nLevel 3 (MAX - Agent chooses specific location):\")\n",
    "        print(\"  north_option1 → [Gemba(8), Limu(7), Fincha(4)]\")\n",
    "        print(\"  north_option2 → [Shambu(7), Ambo(5), Dede(6)]\")\n",
    "        print(\"  south_option1 → [Hossana(9), Duma(6), Worabe(6)]\")\n",
    "        print(\"  south_option2 → [Wolkite(8), Buta Jirra(7), Bekembe(5)]\")\n",
    "        print(\"  south_option3 → [Dilla(9), Kaffa(10), Chiliro(7)]\")\n",
    "        print(\"  east_option1 → [Addis Ababa(3), Adama(5), Mojo(4)]\")\n",
    "        print(\"  east_option2 → [Diredaw(6), Harar(10)]\")\n",
    "        \n",
    "        print(\"\\nTerminal Nodes (Coffee Quality Scores):\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Group by region for better visualization\n",
    "        regions = {\n",
    "            'North Region': ['Gemba', 'Limu', 'Fincha', 'Shambu', 'Ambo', 'Dede'],\n",
    "            'South Region': ['Hossana', 'Duma', 'Worabe', 'Wolkite', 'Buta Jirra', 'Bekembe', 'Dilla', 'Kaffa', 'Chiliro'],\n",
    "            'East Region': ['Addis Ababa', 'Adama', 'Mojo', 'Diredaw', 'Harar']\n",
    "        }\n",
    "        \n",
    "        for region, cities in regions.items():\n",
    "            print(f\"\\n{region}:\")\n",
    "            for city in sorted(cities):\n",
    "                utility = self.get_utility(city)\n",
    "                quality = self._get_quality_description(utility)\n",
    "                print(f\"  {city:15} → Utility: {utility:2} ({quality})\")\n",
    "    \n",
    "    def _get_quality_description(self, utility: int) -> str:\n",
    "        \"\"\"Convert utility to quality description\"\"\"\n",
    "        if utility >= 9:\n",
    "            return \"Premium\"\n",
    "        elif utility >= 7:\n",
    "            return \"Good\"\n",
    "        elif utility >= 5:\n",
    "            return \"Average\"\n",
    "        else:\n",
    "            return \"Basic\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68a365c-bb05-4fef-a30f-1b7d4a776765",
   "metadata": {},
   "source": [
    "### MiniMax Search Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c513fd-a042-4bc5-bc47-f6e016560baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniMaxSearch:\n",
    "    \"\"\"Implementation of MiniMax search algorithm for adversarial coffee search\"\"\"\n",
    "    \n",
    "    def __init__(self, game: CoffeeAdversaryGame):\n",
    "        self.game = game\n",
    "        self.nodes_evaluated = 0\n",
    "        self.max_depth_reached = 0\n",
    "    \n",
    "    def minimax(self, state: str, depth: int = 0, maximizing_player: bool = True) -> Tuple[int, List[str]]:\n",
    "        \"\"\"\n",
    "        MiniMax algorithm implementation\n",
    "        \n",
    "        Args:\n",
    "            state: Current game state\n",
    "            depth: Current depth in game tree\n",
    "            maximizing_player: True if MAX's turn, False if MIN's turn\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (best_value, best_path)\n",
    "        \"\"\"\n",
    "        self.nodes_evaluated += 1\n",
    "        self.max_depth_reached = max(self.max_depth_reached, depth)\n",
    "        \n",
    "        # Check if terminal state\n",
    "        if self.game.is_terminal(state):\n",
    "            utility = self.game.get_utility(state)\n",
    "            return utility, [state]\n",
    "        \n",
    "        # Get children states\n",
    "        children = self.game.get_children(state)\n",
    "        \n",
    "        if maximizing_player:\n",
    "            # MAX player (Agent) wants to maximize coffee quality\n",
    "            best_value = -math.inf\n",
    "            best_path = []\n",
    "            \n",
    "            for child in children:\n",
    "                value, path = self.minimax(child, depth + 1, False)\n",
    "                \n",
    "                if value > best_value:\n",
    "                    best_value = value\n",
    "                    best_path = [state] + path\n",
    "            \n",
    "            return best_value, best_path\n",
    "        \n",
    "        else:\n",
    "            # MIN player (Adversary) wants to minimize coffee quality\n",
    "            best_value = math.inf\n",
    "            best_path = []\n",
    "            \n",
    "            for child in children:\n",
    "                value, path = self.minimax(child, depth + 1, True)\n",
    "                \n",
    "                if value < best_value:\n",
    "                    best_value = value\n",
    "                    best_path = [state] + path\n",
    "            \n",
    "            return best_value, best_path\n",
    "    \n",
    "    def minimax_with_trace(self, state: str, depth: int = 0, \n",
    "                          maximizing_player: bool = True,\n",
    "                          alpha: float = -math.inf,\n",
    "                          beta: float = math.inf,\n",
    "                          path: List[str] = None) -> Tuple[int, List[str], List[Dict]]:\n",
    "        \"\"\"\n",
    "        MiniMax with alpha-beta pruning and detailed tracing\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (best_value, best_path, trace_log)\n",
    "        \"\"\"\n",
    "        if path is None:\n",
    "            path = [state]\n",
    "        \n",
    "        trace_entry = {\n",
    "            'state': state,\n",
    "            'depth': depth,\n",
    "            'player': 'MAX' if maximizing_player else 'MIN',\n",
    "            'alpha': alpha,\n",
    "            'beta': beta,\n",
    "            'value': None,\n",
    "            'pruned': False\n",
    "        }\n",
    "        \n",
    "        self.nodes_evaluated += 1\n",
    "        self.max_depth_reached = max(self.max_depth_reached, depth)\n",
    "        \n",
    "        # Check if terminal state\n",
    "        if self.game.is_terminal(state):\n",
    "            utility = self.game.get_utility(state)\n",
    "            trace_entry['value'] = utility\n",
    "            trace_entry['terminal'] = True\n",
    "            return utility, path, [trace_entry]\n",
    "        \n",
    "        children = self.game.get_children(state)\n",
    "        trace_entry['children'] = children\n",
    "        \n",
    "        if maximizing_player:\n",
    "            # MAX player\n",
    "            best_value = -math.inf\n",
    "            best_child_path = []\n",
    "            child_traces = []\n",
    "            \n",
    "            for child in children:\n",
    "                # Check for alpha-beta pruning\n",
    "                if best_value >= beta:\n",
    "                    trace_entry['pruned'] = True\n",
    "                    trace_entry['prune_reason'] = f\"beta cutoff: {best_value} >= {beta}\"\n",
    "                    break\n",
    "                \n",
    "                value, child_path, child_trace = self.minimax_with_trace(\n",
    "                    child, depth + 1, False, \n",
    "                    max(alpha, best_value), beta,\n",
    "                    path + [child]\n",
    "                )\n",
    "                \n",
    "                child_traces.extend(child_trace)\n",
    "                \n",
    "                if value > best_value:\n",
    "                    best_value = value\n",
    "                    best_child_path = child_path\n",
    "            \n",
    "            trace_entry['value'] = best_value\n",
    "            trace_entry['best_child'] = best_child_path[0] if best_child_path else None\n",
    "            \n",
    "            all_traces = [trace_entry] + child_traces\n",
    "            return best_value, best_child_path, all_traces\n",
    "        \n",
    "        else:\n",
    "            # MIN player\n",
    "            best_value = math.inf\n",
    "            best_child_path = []\n",
    "            child_traces = []\n",
    "            \n",
    "            for child in children:\n",
    "                # Check for alpha-beta pruning\n",
    "                if best_value <= alpha:\n",
    "                    trace_entry['pruned'] = True\n",
    "                    trace_entry['prune_reason'] = f\"alpha cutoff: {best_value} <= {alpha}\"\n",
    "                    break\n",
    "                \n",
    "                value, child_path, child_trace = self.minimax_with_trace(\n",
    "                    child, depth + 1, True,\n",
    "                    alpha, min(beta, best_value),\n",
    "                    path + [child]\n",
    "                )\n",
    "                \n",
    "                child_traces.extend(child_trace)\n",
    "                \n",
    "                if value < best_value:\n",
    "                    best_value = value\n",
    "                    best_child_path = child_path\n",
    "            \n",
    "            trace_entry['value'] = best_value\n",
    "            trace_entry['best_child'] = best_child_path[0] if best_child_path else None\n",
    "            \n",
    "            all_traces = [trace_entry] + child_traces\n",
    "            return best_value, best_child_path, all_traces\n",
    "    \n",
    "    def find_optimal_path(self, start_state: str = 'start') -> Tuple[int, List[str], Dict]:\n",
    "        \"\"\"\n",
    "        Find optimal path using MiniMax\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (optimal_value, optimal_path, statistics)\n",
    "        \"\"\"\n",
    "        print(f\"\\nExecuting MiniMax search from {start_state}...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Reset counters\n",
    "        self.nodes_evaluated = 0\n",
    "        self.max_depth_reached = 0\n",
    "        \n",
    "        # Run MiniMax\n",
    "        optimal_value, optimal_path = self.minimax(start_state, 0, True)\n",
    "        \n",
    "        # Collect statistics\n",
    "        stats = {\n",
    "            'optimal_value': optimal_value,\n",
    "            'path_length': len(optimal_path),\n",
    "            'nodes_evaluated': self.nodes_evaluated,\n",
    "            'max_depth': self.max_depth_reached,\n",
    "            'algorithm': 'MiniMax'\n",
    "        }\n",
    "        \n",
    "        return optimal_value, optimal_path, stats\n",
    "    \n",
    "    def find_optimal_path_alpha_beta(self, start_state: str = 'start') -> Tuple[int, List[str], Dict]:\n",
    "        \"\"\"\n",
    "        Find optimal path using MiniMax with alpha-beta pruning\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (optimal_value, optimal_path, statistics, trace)\n",
    "        \"\"\"\n",
    "        print(f\"\\nExecuting MiniMax with Alpha-Beta Pruning from {start_state}...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Reset counters\n",
    "        self.nodes_evaluated = 0\n",
    "        self.max_depth_reached = 0\n",
    "        \n",
    "        # Run MiniMax with alpha-beta pruning\n",
    "        optimal_value, optimal_path, trace = self.minimax_with_trace(start_state, 0, True)\n",
    "        \n",
    "        # Collect statistics\n",
    "        stats = {\n",
    "            'optimal_value': optimal_value,\n",
    "            'path_length': len(optimal_path),\n",
    "            'nodes_evaluated': self.nodes_evaluated,\n",
    "            'max_depth': self.max_depth_reached,\n",
    "            'pruned_nodes': len([t for t in trace if t.get('pruned', False)]),\n",
    "            'algorithm': 'MiniMax with Alpha-Beta Pruning'\n",
    "        }\n",
    "        \n",
    "        return optimal_value, optimal_path, stats, trace\n",
    "    \n",
    "    def print_optimal_solution(self, optimal_value: int, optimal_path: List[str], stats: Dict):\n",
    "        \"\"\"Print the optimal solution found by MiniMax\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"OPTIMAL SOLUTION FOUND\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        print(f\"\\nOptimal Coffee Quality Score: {optimal_value}/10\")\n",
    "        print(f\"Final Destination: {optimal_path[-1]}\")\n",
    "        \n",
    "        # Get quality description\n",
    "        quality_desc = self.game._get_quality_description(optimal_value)\n",
    "        print(f\"Coffee Quality: {quality_desc}\")\n",
    "        \n",
    "        print(f\"\\nOptimal Path ({len(optimal_path)} steps):\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, state in enumerate(optimal_path):\n",
    "            if i == 0:\n",
    "                print(f\"Start: {state}\")\n",
    "            elif self.game.is_terminal(state):\n",
    "                utility = self.game.get_utility(state)\n",
    "                quality = self.game._get_quality_description(utility)\n",
    "                print(f\"  → Terminal: {state} (Utility: {utility}, Quality: {quality})\")\n",
    "            else:\n",
    "                player = self.game.get_player(state)\n",
    "                print(f\"  → {player}: {state}\")\n",
    "        \n",
    "        print(\"\\nGame Analysis:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Show decision reasoning\n",
    "        if len(optimal_path) >= 3:\n",
    "            print(\"Decision Process:\")\n",
    "            print(f\"  1. Agent (MAX) chooses: {optimal_path[1]}\")\n",
    "            print(f\"  2. Adversary (MIN) responds: {optimal_path[2]}\")\n",
    "            print(f\"  3. Agent (MAX) selects: {optimal_path[3]}\")\n",
    "        \n",
    "        print(f\"\\nSearch Statistics:\")\n",
    "        print(f\"  Nodes evaluated: {stats['nodes_evaluated']}\")\n",
    "        print(f\"  Maximum depth: {stats['max_depth']}\")\n",
    "        print(f\"  Path length: {stats['path_length']}\")\n",
    "        if 'pruned_nodes' in stats:\n",
    "            print(f\"  Pruned nodes: {stats['pruned_nodes']}\")\n",
    "        \n",
    "        print(\"\\nStrategy Explanation:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"The Agent (MAX) chooses the path that guarantees the highest\")\n",
    "        print(\"coffee quality, assuming the Adversary (MIN) plays optimally\")\n",
    "        print(\"to minimize the Agent's coffee quality.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51d3dfd-5c1d-403c-8ac6-cd56eb9135c3",
   "metadata": {},
   "source": [
    "### Execute MiniMax Search\n",
    "Initialize the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1fee87f-74b1-4a5b-9bdb-20b373897ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COFFEE ADVERSARY GAME TREE ===\n",
      "\n",
      "Game Structure:\n",
      "--------------------------------------------------\n",
      "Level 1 (MAX - Agent chooses region):\n",
      "  start → [region_north, region_south, region_east]\n",
      "\n",
      "Level 2 (MIN - Adversary chooses sub-region):\n",
      "  region_north → [north_option1, north_option2]\n",
      "  region_south → [south_option1, south_option2, south_option3]\n",
      "  region_east → [east_option1, east_option2]\n",
      "\n",
      "Level 3 (MAX - Agent chooses specific location):\n",
      "  north_option1 → [Gemba(8), Limu(7), Fincha(4)]\n",
      "  north_option2 → [Shambu(7), Ambo(5), Dede(6)]\n",
      "  south_option1 → [Hossana(9), Duma(6), Worabe(6)]\n",
      "  south_option2 → [Wolkite(8), Buta Jirra(7), Bekembe(5)]\n",
      "  south_option3 → [Dilla(9), Kaffa(10), Chiliro(7)]\n",
      "  east_option1 → [Addis Ababa(3), Adama(5), Mojo(4)]\n",
      "  east_option2 → [Diredaw(6), Harar(10)]\n",
      "\n",
      "Terminal Nodes (Coffee Quality Scores):\n",
      "--------------------------------------------------\n",
      "\n",
      "North Region:\n",
      "  Ambo            → Utility:  5 (Average)\n",
      "  Dede            → Utility:  6 (Average)\n",
      "  Fincha          → Utility:  4 (Basic)\n",
      "  Gemba           → Utility:  8 (Good)\n",
      "  Limu            → Utility:  7 (Good)\n",
      "  Shambu          → Utility:  7 (Good)\n",
      "\n",
      "South Region:\n",
      "  Bekembe         → Utility:  5 (Average)\n",
      "  Buta Jirra      → Utility:  7 (Good)\n",
      "  Chiliro         → Utility:  7 (Good)\n",
      "  Dilla           → Utility:  9 (Premium)\n",
      "  Duma            → Utility:  6 (Average)\n",
      "  Hossana         → Utility:  9 (Premium)\n",
      "  Kaffa           → Utility: 10 (Premium)\n",
      "  Wolkite         → Utility:  8 (Good)\n",
      "  Worabe          → Utility:  6 (Average)\n",
      "\n",
      "East Region:\n",
      "  Adama           → Utility:  5 (Average)\n",
      "  Addis Ababa     → Utility:  3 (Basic)\n",
      "  Diredaw         → Utility:  6 (Average)\n",
      "  Harar           → Utility: 10 (Premium)\n",
      "  Mojo            → Utility:  4 (Basic)\n",
      "\n",
      "======================================================================\n",
      "BASIC MINIMAX SEARCH\n",
      "======================================================================\n",
      "\n",
      "Executing MiniMax search from start...\n",
      "------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "OPTIMAL SOLUTION FOUND\n",
      "======================================================================\n",
      "\n",
      "Optimal Coffee Quality Score: 8/10\n",
      "Final Destination: Wolkite\n",
      "Coffee Quality: Good\n",
      "\n",
      "Optimal Path (4 steps):\n",
      "--------------------------------------------------\n",
      "Start: start\n",
      "  → MIN: region_south\n",
      "  → MAX: south_option2\n",
      "  → Terminal: Wolkite (Utility: 8, Quality: Good)\n",
      "\n",
      "Game Analysis:\n",
      "--------------------------------------------------\n",
      "Decision Process:\n",
      "  1. Agent (MAX) chooses: region_south\n",
      "  2. Adversary (MIN) responds: south_option2\n",
      "  3. Agent (MAX) selects: Wolkite\n",
      "\n",
      "Search Statistics:\n",
      "  Nodes evaluated: 31\n",
      "  Maximum depth: 3\n",
      "  Path length: 4\n",
      "\n",
      "Strategy Explanation:\n",
      "--------------------------------------------------\n",
      "The Agent (MAX) chooses the path that guarantees the highest\n",
      "coffee quality, assuming the Adversary (MIN) plays optimally\n",
      "to minimize the Agent's coffee quality.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "coffee_game = CoffeeAdversaryGame()\n",
    "\n",
    "# Display game tree\n",
    "coffee_game.display_game_tree()\n",
    "\n",
    "# Initialize MiniMax solver\n",
    "minimax_solver = MiniMaxSearch(coffee_game)\n",
    "\n",
    "# Find optimal path using basic MiniMax\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BASIC MINIMAX SEARCH\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "optimal_value, optimal_path, stats = minimax_solver.find_optimal_path('start')\n",
    "minimax_solver.print_optimal_solution(optimal_value, optimal_path, stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63425ea4-43ef-4eac-b7d4-2adfc29566f0",
   "metadata": {},
   "source": [
    "### Execute MiniMax with Alpha-Beta Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0308b75-dae3-46a7-87e3-74fb6b970dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MINIMAX WITH ALPHA-BETA PRUNING\n",
      "======================================================================\n",
      "\n",
      "Executing MiniMax with Alpha-Beta Pruning from start...\n",
      "------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "OPTIMAL SOLUTION FOUND\n",
      "======================================================================\n",
      "\n",
      "Optimal Coffee Quality Score: 8/10\n",
      "Final Destination: Wolkite\n",
      "Coffee Quality: Good\n",
      "\n",
      "Optimal Path (4 steps):\n",
      "--------------------------------------------------\n",
      "Start: start\n",
      "  → MIN: region_south\n",
      "  → MAX: south_option2\n",
      "  → Terminal: Wolkite (Utility: 8, Quality: Good)\n",
      "\n",
      "Game Analysis:\n",
      "--------------------------------------------------\n",
      "Decision Process:\n",
      "  1. Agent (MAX) chooses: region_south\n",
      "  2. Adversary (MIN) responds: south_option2\n",
      "  3. Agent (MAX) selects: Wolkite\n",
      "\n",
      "Search Statistics:\n",
      "  Nodes evaluated: 26\n",
      "  Maximum depth: 3\n",
      "  Path length: 4\n",
      "  Pruned nodes: 2\n",
      "\n",
      "Strategy Explanation:\n",
      "--------------------------------------------------\n",
      "The Agent (MAX) chooses the path that guarantees the highest\n",
      "coffee quality, assuming the Adversary (MIN) plays optimally\n",
      "to minimize the Agent's coffee quality.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MINIMAX WITH ALPHA-BETA PRUNING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "optimal_value_ab, optimal_path_ab, stats_ab, trace = minimax_solver.find_optimal_path_alpha_beta('start')\n",
    "minimax_solver.print_optimal_solution(optimal_value_ab, optimal_path_ab, stats_ab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60192f64-6393-44c9-bf33-22a222363bae",
   "metadata": {},
   "source": [
    "### Detailed Search Trace Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba52b3e5-540d-406f-82f8-df46f82d891d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SEARCH TRACE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Node Statistics:\n",
      "  Total nodes in trace: 26\n",
      "  MAX nodes (Agent): 7\n",
      "  MIN nodes (Adversary): 19\n",
      "  Terminal nodes: 16\n",
      "  Pruned nodes: 2\n",
      "  Pruning efficiency: 7.7%\n",
      "\n",
      "Examples of Pruned Subtrees:\n",
      "  1. State: south_option3\n",
      "     Reason: beta cutoff: 9 >= 8\n",
      "     Depth: 2\n",
      "  2. State: region_east\n",
      "     Reason: alpha cutoff: 5 <= 8\n",
      "     Depth: 1\n",
      "\n",
      "Decision Tree with Backed-up Values:\n",
      "--------------------------------------------------\n",
      "\n",
      "Depth 0:\n",
      "  MAX: start                [Value: 8]\n",
      "\n",
      "Depth 1:\n",
      "  MIN: region_north         [Value: 7]\n",
      "  MIN: region_south         [Value: 8]\n",
      "  MIN: region_east          [PRUNED]\n",
      "\n",
      "Depth 2:\n",
      "  MAX: north_option1        [Value: 8]\n",
      "  MAX: north_option2        [Value: 7]\n",
      "  MAX: south_option1        [Value: 9]\n",
      "  MAX: south_option2        [Value: 8]\n",
      "  MAX: south_option3        [PRUNED]\n",
      "  MAX: east_option1         [Value: 5]\n",
      "\n",
      "Depth 3:\n",
      "  MIN: Gemba                [TERMINAL: 8]\n",
      "  MIN: Limu                 [TERMINAL: 7]\n",
      "  MIN: Fincha               [TERMINAL: 4]\n",
      "  MIN: Shambu               [TERMINAL: 7]\n",
      "  MIN: Ambo                 [TERMINAL: 5]\n",
      "  MIN: Dede                 [TERMINAL: 6]\n",
      "  MIN: Hossana              [TERMINAL: 9]\n",
      "  MIN: Duma                 [TERMINAL: 6]\n",
      "  MIN: Worabe               [TERMINAL: 6]\n",
      "  MIN: Wolkite              [TERMINAL: 8]\n",
      "  MIN: Buta Jirra           [TERMINAL: 7]\n",
      "  MIN: Bekembe              [TERMINAL: 5]\n",
      "  MIN: Dilla                [TERMINAL: 9]\n",
      "  MIN: Addis Ababa          [TERMINAL: 3]\n",
      "  MIN: Adama                [TERMINAL: 5]\n",
      "  MIN: Mojo                 [TERMINAL: 4]\n"
     ]
    }
   ],
   "source": [
    "def analyze_search_trace(trace: List[Dict]):\n",
    "    \"\"\"Analyze the search trace from alpha-beta pruning\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SEARCH TRACE ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Count nodes by type\n",
    "    max_nodes = len([t for t in trace if t.get('player') == 'MAX'])\n",
    "    min_nodes = len([t for t in trace if t.get('player') == 'MIN'])\n",
    "    terminal_nodes = len([t for t in trace if t.get('terminal', False)])\n",
    "    pruned_nodes = len([t for t in trace if t.get('pruned', False)])\n",
    "    \n",
    "    print(f\"\\nNode Statistics:\")\n",
    "    print(f\"  Total nodes in trace: {len(trace)}\")\n",
    "    print(f\"  MAX nodes (Agent): {max_nodes}\")\n",
    "    print(f\"  MIN nodes (Adversary): {min_nodes}\")\n",
    "    print(f\"  Terminal nodes: {terminal_nodes}\")\n",
    "    print(f\"  Pruned nodes: {pruned_nodes}\")\n",
    "    print(f\"  Pruning efficiency: {(pruned_nodes/len(trace))*100:.1f}%\")\n",
    "    \n",
    "    # Show pruning examples\n",
    "    pruned_examples = [t for t in trace if t.get('pruned', False)]\n",
    "    if pruned_examples:\n",
    "        print(f\"\\nExamples of Pruned Subtrees:\")\n",
    "        for i, example in enumerate(pruned_examples[:3]):  # Show first 3\n",
    "            print(f\"  {i+1}. State: {example['state']}\")\n",
    "            print(f\"     Reason: {example.get('prune_reason', 'Unknown')}\")\n",
    "            print(f\"     Depth: {example['depth']}\")\n",
    "    \n",
    "    # Show decision tree with values\n",
    "    print(f\"\\nDecision Tree with Backed-up Values:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Group by depth\n",
    "    by_depth = {}\n",
    "    for entry in trace:\n",
    "        depth = entry['depth']\n",
    "        if depth not in by_depth:\n",
    "            by_depth[depth] = []\n",
    "        by_depth[depth].append(entry)\n",
    "    \n",
    "    for depth in sorted(by_depth.keys()):\n",
    "        entries = by_depth[depth]\n",
    "        print(f\"\\nDepth {depth}:\")\n",
    "        for entry in entries:\n",
    "            if entry.get('pruned', False):\n",
    "                status = \"[PRUNED]\"\n",
    "            elif entry.get('terminal', False):\n",
    "                status = f\"[TERMINAL: {entry['value']}]\"\n",
    "            else:\n",
    "                status = f\"[Value: {entry.get('value', '?')}]\"\n",
    "            \n",
    "            player = entry.get('player', 'TERM')\n",
    "            print(f\"  {player}: {entry['state']:20} {status}\")\n",
    "\n",
    "# %%\n",
    "# Analyze the trace\n",
    "if 'trace' in locals():\n",
    "    analyze_search_trace(trace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea45f7-10ee-4bb6-8d58-b624dc5546df",
   "metadata": {},
   "source": [
    "### Game Theory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e6f6ed5-a215-496a-9444-2e59fd3a4b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GAME THEORY ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "1. AGENT'S (MAX) PERSPECTIVE:\n",
      "--------------------------------------------------\n",
      "Initial choices: ['region_north', 'region_south', 'region_east']\n",
      "  region_north: Guaranteed minimum = 7\n",
      "  region_south: Guaranteed minimum = 8\n",
      "  region_east: Guaranteed minimum = 5\n",
      "\n",
      "2. ADVERSARY'S (MIN) PERSPECTIVE:\n",
      "--------------------------------------------------\n",
      "Adversary's optimal response strategy:\n",
      "  If Agent chooses region_north, Adversary should choose north_option2\n",
      "    Resulting maximum for Agent: 7\n",
      "  If Agent chooses region_south, Adversary should choose south_option2\n",
      "    Resulting maximum for Agent: 8\n",
      "  If Agent chooses region_east, Adversary should choose east_option1\n",
      "    Resulting maximum for Agent: 5\n",
      "\n",
      "3. NASH EQUILIBRIUM ANALYSIS:\n",
      "--------------------------------------------------\n",
      "In this zero-sum game:\n",
      "  • Agent's optimal strategy: Choose path with highest minimax value\n",
      "  • Adversary's optimal strategy: Choose path that minimizes Agent's maximum\n",
      "  • The solution found by MiniMax is a Nash equilibrium\n",
      "\n",
      "4. DOMINATED STRATEGIES:\n",
      "--------------------------------------------------\n",
      "Checking for dominated strategies...\n",
      "  region_north is dominated by another strategy\n",
      "  region_south is not dominated\n",
      "  region_east is dominated by another strategy\n",
      "\n",
      "======================================================================\n",
      "GAMEPLAY SIMULATIONS\n",
      "======================================================================\n",
      "\n",
      "Simulation 1: Optimal vs Optimal\n",
      "\n",
      "5. GAMEPLAY SIMULATION:\n",
      "--------------------------------------------------\n",
      "Agent strategy: optimal\n",
      "Adversary strategy: optimal\n",
      "\n",
      "Turn 1: Agent (MAX) moves from start\n",
      "\n",
      "Executing MiniMax search from start...\n",
      "------------------------------------------------------------\n",
      "  Agent chooses: region_south\n",
      "\n",
      "Turn 2: Adversary (MIN) moves from region_south\n",
      "  Adversary chooses: south_option2\n",
      "\n",
      "Turn 3: Agent (MAX) final move from south_option2\n",
      "  Agent chooses: Wolkite\n",
      "  Coffee Quality: 8\n",
      "\n",
      "Final Path: start → region_south → south_option2 → Wolkite\n",
      "Final Coffee Quality: 8\n",
      "\n",
      "Simulation 2: Greedy Agent vs Optimal Adversary\n",
      "\n",
      "5. GAMEPLAY SIMULATION:\n",
      "--------------------------------------------------\n",
      "Agent strategy: greedy\n",
      "Adversary strategy: optimal\n",
      "\n",
      "Turn 1: Agent (MAX) moves from start\n",
      "  Agent chooses: region_south\n",
      "\n",
      "Turn 2: Adversary (MIN) moves from region_south\n",
      "  Adversary chooses: south_option2\n",
      "\n",
      "Turn 3: Agent (MAX) final move from south_option2\n",
      "  Agent chooses: Wolkite\n",
      "  Coffee Quality: 8\n",
      "\n",
      "Final Path: start → region_south → south_option2 → Wolkite\n",
      "Final Coffee Quality: 8\n",
      "\n",
      "Simulation 3: Optimal Agent vs Random Adversary\n",
      "\n",
      "5. GAMEPLAY SIMULATION:\n",
      "--------------------------------------------------\n",
      "Agent strategy: optimal\n",
      "Adversary strategy: random\n",
      "\n",
      "Turn 1: Agent (MAX) moves from start\n",
      "\n",
      "Executing MiniMax search from start...\n",
      "------------------------------------------------------------\n",
      "  Agent chooses: region_south\n",
      "\n",
      "Turn 2: Adversary (MIN) moves from region_south\n",
      "  Adversary chooses: south_option2\n",
      "\n",
      "Turn 3: Agent (MAX) final move from south_option2\n",
      "  Agent chooses: Wolkite\n",
      "  Coffee Quality: 8\n",
      "\n",
      "Final Path: start → region_south → south_option2 → Wolkite\n",
      "Final Coffee Quality: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class GameTheoryAnalyzer:\n",
    "    \"\"\"Analyze the game from game theory perspective\"\"\"\n",
    "    \n",
    "    def __init__(self, game: CoffeeAdversaryGame):\n",
    "        self.game = game\n",
    "    \n",
    "    def analyze_strategies(self):\n",
    "        \"\"\"Analyze optimal strategies for both players\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"GAME THEORY ANALYSIS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Analyze from Agent's perspective (MAX)\n",
    "        print(\"\\n1. AGENT'S (MAX) PERSPECTIVE:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        initial_options = self.game.get_children('start')\n",
    "        print(f\"Initial choices: {initial_options}\")\n",
    "        \n",
    "        for option in initial_options:\n",
    "            children = self.game.get_children(option)\n",
    "            min_utilities = []\n",
    "            \n",
    "            for child in children:\n",
    "                grandchildren = self.game.get_children(child)\n",
    "                if grandchildren:\n",
    "                    # Agent will choose max from grandchildren\n",
    "                    grandchild_utilities = [self.game.get_utility(gc) for gc in grandchildren]\n",
    "                    min_utilities.append(max(grandchild_utilities))\n",
    "            \n",
    "            if min_utilities:\n",
    "                guaranteed_value = min(min_utilities)  # Adversary chooses min\n",
    "                print(f\"  {option}: Guaranteed minimum = {guaranteed_value}\")\n",
    "        \n",
    "        # Analyze from Adversary's perspective (MIN)\n",
    "        print(\"\\n2. ADVERSARY'S (MIN) PERSPECTIVE:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Adversary wants to minimize Agent's maximum\n",
    "        print(\"Adversary's optimal response strategy:\")\n",
    "        \n",
    "        # For each Agent's initial move, find Adversary's best response\n",
    "        for agent_move in initial_options:\n",
    "            adversary_options = self.game.get_children(agent_move)\n",
    "            best_adversary_move = None\n",
    "            best_adversary_value = math.inf\n",
    "            \n",
    "            for adv_move in adversary_options:\n",
    "                agent_final_options = self.game.get_children(adv_move)\n",
    "                if agent_final_options:\n",
    "                    # Agent will choose max from final options\n",
    "                    max_utility = max([self.game.get_utility(op) for op in agent_final_options])\n",
    "                    \n",
    "                    if max_utility < best_adversary_value:\n",
    "                        best_adversary_value = max_utility\n",
    "                        best_adversary_move = adv_move\n",
    "            \n",
    "            if best_adversary_move:\n",
    "                print(f\"  If Agent chooses {agent_move}, Adversary should choose {best_adversary_move}\")\n",
    "                print(f\"    Resulting maximum for Agent: {best_adversary_value}\")\n",
    "        \n",
    "        print(\"\\n3. NASH EQUILIBRIUM ANALYSIS:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Find pure strategy Nash equilibrium\n",
    "        print(\"In this zero-sum game:\")\n",
    "        print(\"  • Agent's optimal strategy: Choose path with highest minimax value\")\n",
    "        print(\"  • Adversary's optimal strategy: Choose path that minimizes Agent's maximum\")\n",
    "        print(\"  • The solution found by MiniMax is a Nash equilibrium\")\n",
    "        \n",
    "        print(\"\\n4. DOMINATED STRATEGIES:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Check for dominated strategies\n",
    "        print(\"Checking for dominated strategies...\")\n",
    "        \n",
    "        # Agent's initial moves\n",
    "        agent_payoffs = {}\n",
    "        for agent_move in initial_options:\n",
    "            adversary_responses = self.game.get_children(agent_move)\n",
    "            worst_case = math.inf\n",
    "            \n",
    "            for adv_response in adversary_responses:\n",
    "                agent_final = self.game.get_children(adv_response)\n",
    "                if agent_final:\n",
    "                    best_final = max([self.game.get_utility(f) for f in agent_final])\n",
    "                    worst_case = min(worst_case, best_final)\n",
    "            \n",
    "            agent_payoffs[agent_move] = worst_case\n",
    "        \n",
    "        # Check if any strategy is dominated\n",
    "        for move1, payoff1 in agent_payoffs.items():\n",
    "            dominated = False\n",
    "            for move2, payoff2 in agent_payoffs.items():\n",
    "                if move1 != move2 and payoff1 <= payoff2:\n",
    "                    # Check if move1 is strictly worse in all scenarios\n",
    "                    dominated = True\n",
    "                    break\n",
    "            \n",
    "            if dominated:\n",
    "                print(f\"  {move1} is dominated by another strategy\")\n",
    "            else:\n",
    "                print(f\"  {move1} is not dominated\")\n",
    "    \n",
    "    def simulate_gameplay(self, agent_strategy: str = 'optimal', \n",
    "                         adversary_strategy: str = 'optimal'):\n",
    "        \"\"\"Simulate gameplay with different strategies\"\"\"\n",
    "        \n",
    "        print(f\"\\n5. GAMEPLAY SIMULATION:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        print(f\"Agent strategy: {agent_strategy}\")\n",
    "        print(f\"Adversary strategy: {adversary_strategy}\")\n",
    "        \n",
    "        # Current state\n",
    "        current_state = 'start'\n",
    "        path = [current_state]\n",
    "        \n",
    "        print(f\"\\nTurn 1: Agent (MAX) moves from {current_state}\")\n",
    "        \n",
    "        # Agent's move\n",
    "        if agent_strategy == 'optimal':\n",
    "            # Use MiniMax to find optimal move\n",
    "            minimax_solver = MiniMaxSearch(self.game)\n",
    "            _, optimal_path, _ = minimax_solver.find_optimal_path(current_state)\n",
    "            agent_move = optimal_path[1]\n",
    "        elif agent_strategy == 'greedy':\n",
    "            # Choose move with highest immediate potential\n",
    "            options = self.game.get_children(current_state)\n",
    "            # Evaluate each option\n",
    "            best_move = None\n",
    "            best_value = -math.inf\n",
    "            \n",
    "            for option in options:\n",
    "                # Simple heuristic: average of terminal utilities in subtree\n",
    "                total_utility = 0\n",
    "                count = 0\n",
    "                \n",
    "                for child in self.game.get_children(option):\n",
    "                    for terminal in self.game.get_children(child):\n",
    "                        total_utility += self.game.get_utility(terminal)\n",
    "                        count += 1\n",
    "                \n",
    "                if count > 0:\n",
    "                    avg_utility = total_utility / count\n",
    "                    if avg_utility > best_value:\n",
    "                        best_value = avg_utility\n",
    "                        best_move = option\n",
    "            \n",
    "            agent_move = best_move\n",
    "        else:\n",
    "            # Random move\n",
    "            import random\n",
    "            options = self.game.get_children(current_state)\n",
    "            agent_move = random.choice(options)\n",
    "        \n",
    "        current_state = agent_move\n",
    "        path.append(current_state)\n",
    "        print(f\"  Agent chooses: {agent_move}\")\n",
    "        \n",
    "        # Adversary's move\n",
    "        print(f\"\\nTurn 2: Adversary (MIN) moves from {current_state}\")\n",
    "        \n",
    "        if adversary_strategy == 'optimal':\n",
    "            # Find move that minimizes Agent's maximum\n",
    "            options = self.game.get_children(current_state)\n",
    "            best_move = None\n",
    "            best_value = math.inf\n",
    "            \n",
    "            for option in options:\n",
    "                # Agent will maximize from next level\n",
    "                agent_options = self.game.get_children(option)\n",
    "                if agent_options:\n",
    "                    max_utility = max([self.game.get_utility(op) for op in agent_options])\n",
    "                    if max_utility < best_value:\n",
    "                        best_value = max_utility\n",
    "                        best_move = option\n",
    "        elif adversary_strategy == 'random':\n",
    "            import random\n",
    "            options = self.game.get_children(current_state)\n",
    "            best_move = random.choice(options)\n",
    "        else:\n",
    "            # Greedy adversary\n",
    "            options = self.game.get_children(current_state)\n",
    "            best_move = None\n",
    "            worst_for_agent = math.inf\n",
    "            \n",
    "            for option in options:\n",
    "                agent_options = self.game.get_children(option)\n",
    "                if agent_options:\n",
    "                    # Adversary wants to give Agent the worst options\n",
    "                    min_utility = min([self.game.get_utility(op) for op in agent_options])\n",
    "                    if min_utility < worst_for_agent:\n",
    "                        worst_for_agent = min_utility\n",
    "                        best_move = option\n",
    "        \n",
    "        current_state = best_move\n",
    "        path.append(current_state)\n",
    "        print(f\"  Adversary chooses: {best_move}\")\n",
    "        \n",
    "        # Agent's final move\n",
    "        print(f\"\\nTurn 3: Agent (MAX) final move from {current_state}\")\n",
    "        \n",
    "        options = self.game.get_children(current_state)\n",
    "        if options:\n",
    "            # Agent chooses highest utility\n",
    "            best_final = None\n",
    "            best_utility = -math.inf\n",
    "            \n",
    "            for option in options:\n",
    "                utility = self.game.get_utility(option)\n",
    "                if utility > best_utility:\n",
    "                    best_utility = utility\n",
    "                    best_final = option\n",
    "            \n",
    "            current_state = best_final\n",
    "            path.append(current_state)\n",
    "            print(f\"  Agent chooses: {best_final}\")\n",
    "            print(f\"  Coffee Quality: {best_utility}\")\n",
    "        \n",
    "        print(f\"\\nFinal Path: {' → '.join(path)}\")\n",
    "        print(f\"Final Coffee Quality: {best_utility}\")\n",
    "        \n",
    "        return path, best_utility\n",
    "\n",
    "# %%\n",
    "# Perform game theory analysis\n",
    "analyzer = GameTheoryAnalyzer(coffee_game)\n",
    "analyzer.analyze_strategies()\n",
    "\n",
    "# Simulate different gameplay scenarios\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GAMEPLAY SIMULATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Simulation 1: Optimal vs Optimal\n",
    "print(\"\\nSimulation 1: Optimal vs Optimal\")\n",
    "path1, utility1 = analyzer.simulate_gameplay('optimal', 'optimal')\n",
    "\n",
    "# Simulation 2: Greedy vs Optimal\n",
    "print(\"\\nSimulation 2: Greedy Agent vs Optimal Adversary\")\n",
    "path2, utility2 = analyzer.simulate_gameplay('greedy', 'optimal')\n",
    "\n",
    "# Simulation 3: Optimal vs Random\n",
    "print(\"\\nSimulation 3: Optimal Agent vs Random Adversary\")\n",
    "path3, utility3 = analyzer.simulate_gameplay('optimal', 'random')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd8958-8747-488d-a2e0-109ba759423b",
   "metadata": {},
   "source": [
    "### Alternative Game Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ed369ec-6b84-4b90-b1d3-2c51297170fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ExtendedCoffeeGame:\n",
    "    \"\"\"Extended game with more complex structure and uncertainties\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Add probabilities and uncertainties\n",
    "        self.game_tree = {\n",
    "            'start': {\n",
    "                'player': 'MAX',\n",
    "                'children': {\n",
    "                    'north': {'probability': 0.3, 'children': ['north1', 'north2']},\n",
    "                    'south': {'probability': 0.5, 'children': ['south1', 'south2', 'south3']},\n",
    "                    'east': {'probability': 0.2, 'children': ['east1', 'east2']}\n",
    "                }\n",
    "            },\n",
    "            # ... rest of tree with probabilities\n",
    "        }\n",
    "        \n",
    "        # Add weather effects on coffee quality\n",
    "        self.weather_effects = {\n",
    "            'good': 1.2,    # 20% increase in quality\n",
    "            'normal': 1.0,  # No change\n",
    "            'bad': 0.8      # 20% decrease\n",
    "        }\n",
    "    \n",
    "    def expectiminimax(self, state: str, depth: int, player: str):\n",
    "        \"\"\"Expectiminimax for games with chance nodes\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8629db-970d-4e61-baaa-bcda91f205cf",
   "metadata": {},
   "source": [
    "### Visualization of MiniMax Decision Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23ca6f94-34ff-4447-adab-a6e4310ac796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MINIMAX DECISION PROCESS VISUALIZATION\n",
      "======================================================================\n",
      "\n",
      "Consider this simplified game tree:\n",
      "\n",
      "          start (MAX)\n",
      "          /     |     \\\n",
      "    north    south    east (MIN)\n",
      "      |        |        |\n",
      "    [8,7,4]  [9,6,6]  [3,5,4] (MAX - chooses max)\n",
      "    \n",
      "\n",
      "MiniMax Calculation Process:\n",
      "--------------------------------------------------\n",
      "1. From terminal nodes, propagate values upward:\n",
      "   north subtree: MAX chooses max(8,7,4) = 8\n",
      "   south subtree: MAX chooses max(9,6,6) = 9\n",
      "   east subtree:  MAX chooses max(3,5,4) = 5\n",
      "\n",
      "2. At MIN level (adversary chooses):\n",
      "   MIN chooses min(8, 9, 5) = 5\n",
      "\n",
      "3. At root (MAX chooses initial move):\n",
      "   Agent should choose path leading to value 5\n",
      "   This means starting with 'east' region\n",
      "\n",
      "Key Insight:\n",
      "--------------------------------------------------\n",
      "MiniMax assumes optimal play from both sides.\n",
      "Agent chooses move that maximizes minimum guaranteed payoff.\n",
      "Adversary chooses move that minimizes Agent's maximum payoff.\n",
      "\n",
      "Actual Game Calculation:\n",
      "--------------------------------------------------\n",
      "\n",
      "Executing MiniMax search from start...\n",
      "------------------------------------------------------------\n",
      "Optimal value: 8\n",
      "Optimal path: start → region_south → south_option2 → Wolkite\n",
      "\n",
      "Why this is optimal:\n",
      "• Starting with region_south guarantees at least 8\n",
      "• Any other initial move gives the adversary chance to force lower quality\n",
      "• This is the maximin strategy: maximize the minimum guaranteed payoff\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def visualize_minimax_decisions():\n",
    "    \"\"\"Visualize how MiniMax makes decisions\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"MINIMAX DECISION PROCESS VISUALIZATION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Recreate a simplified example\n",
    "    print(\"\\nConsider this simplified game tree:\")\n",
    "    print(\"\"\"\n",
    "          start (MAX)\n",
    "          /     |     \\\\\n",
    "    north    south    east (MIN)\n",
    "      |        |        |\n",
    "    [8,7,4]  [9,6,6]  [3,5,4] (MAX - chooses max)\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\nMiniMax Calculation Process:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(\"1. From terminal nodes, propagate values upward:\")\n",
    "    print(\"   north subtree: MAX chooses max(8,7,4) = 8\")\n",
    "    print(\"   south subtree: MAX chooses max(9,6,6) = 9\")\n",
    "    print(\"   east subtree:  MAX chooses max(3,5,4) = 5\")\n",
    "    \n",
    "    print(\"\\n2. At MIN level (adversary chooses):\")\n",
    "    print(\"   MIN chooses min(8, 9, 5) = 5\")\n",
    "    \n",
    "    print(\"\\n3. At root (MAX chooses initial move):\")\n",
    "    print(\"   Agent should choose path leading to value 5\")\n",
    "    print(\"   This means starting with 'east' region\")\n",
    "    \n",
    "    print(\"\\nKey Insight:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"MiniMax assumes optimal play from both sides.\")\n",
    "    print(\"Agent chooses move that maximizes minimum guaranteed payoff.\")\n",
    "    print(\"Adversary chooses move that minimizes Agent's maximum payoff.\")\n",
    "    \n",
    "    # Show actual calculation from our game\n",
    "    print(\"\\nActual Game Calculation:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    minimax_solver = MiniMaxSearch(coffee_game)\n",
    "    optimal_value, optimal_path, _ = minimax_solver.find_optimal_path('start')\n",
    "    \n",
    "    print(f\"Optimal value: {optimal_value}\")\n",
    "    print(f\"Optimal path: {' → '.join(optimal_path)}\")\n",
    "    \n",
    "    # Explain why this is optimal\n",
    "    print(f\"\\nWhy this is optimal:\")\n",
    "    print(f\"• Starting with {optimal_path[1]} guarantees at least {optimal_value}\")\n",
    "    print(f\"• Any other initial move gives the adversary chance to force lower quality\")\n",
    "    print(f\"• This is the maximin strategy: maximize the minimum guaranteed payoff\")\n",
    "\n",
    "# %%\n",
    "visualize_minimax_decisions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2c599b-016a-4a07-a4bb-490985f5144a",
   "metadata": {},
   "source": [
    "### Performance Comparison: MiniMax vs Alpha-Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9414e2a2-3994-4d02-83e5-7e839d2c7992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ALGORITHM PERFORMANCE COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Executing MiniMax search from start...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Executing MiniMax with Alpha-Beta Pruning from start...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Comparison Results:\n",
      "--------------------------------------------------\n",
      "Metric                    MiniMax         Alpha-Beta      Improvement    \n",
      "----------------------------------------------------------------------\n",
      "Nodes Evaluated           31              26              16.1%\n",
      "Optimal Value             8               8               Same           \n",
      "Pruned Nodes              N/A             2               N/A            \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Key Findings:\n",
      "1. Both algorithms find the same optimal solution\n",
      "2. Alpha-Beta pruning evaluates significantly fewer nodes\n",
      "3. Pruning efficiency depends on move ordering\n",
      "4. Alpha-Beta is always at least as good as MiniMax\n",
      "\n",
      "When to use which algorithm:\n",
      "• MiniMax: Simple implementation, small game trees\n",
      "• Alpha-Beta: Large game trees, needs optimization\n",
      "• Expectiminimax: Games with chance elements\n",
      "• Monte Carlo Tree Search: Very large game trees\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compare_algorithms():\n",
    "    \"\"\"Compare MiniMax and Alpha-Beta pruning performance\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ALGORITHM PERFORMANCE COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Run both algorithms\n",
    "    coffee_game = CoffeeAdversaryGame()\n",
    "    \n",
    "    # Basic MiniMax\n",
    "    minimax_solver = MiniMaxSearch(coffee_game)\n",
    "    _, _, stats_mm = minimax_solver.find_optimal_path('start')\n",
    "    \n",
    "    # Alpha-Beta\n",
    "    minimax_solver_ab = MiniMaxSearch(coffee_game)\n",
    "    _, _, stats_ab, _ = minimax_solver_ab.find_optimal_path_alpha_beta('start')\n",
    "    \n",
    "    print(\"\\nComparison Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(f\"{'Metric':<25} {'MiniMax':<15} {'Alpha-Beta':<15} {'Improvement':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    nodes_mm = stats_mm['nodes_evaluated']\n",
    "    nodes_ab = stats_ab['nodes_evaluated']\n",
    "    improvement = ((nodes_mm - nodes_ab) / nodes_mm) * 100\n",
    "    \n",
    "    print(f\"{'Nodes Evaluated':<25} {nodes_mm:<15} {nodes_ab:<15} {improvement:.1f}%\")\n",
    "    print(f\"{'Optimal Value':<25} {stats_mm['optimal_value']:<15} {stats_ab['optimal_value']:<15} {'Same':<15}\")\n",
    "    \n",
    "    if 'pruned_nodes' in stats_ab:\n",
    "        print(f\"{'Pruned Nodes':<25} {'N/A':<15} {stats_ab['pruned_nodes']:<15} {'N/A':<15}\")\n",
    "    \n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    print(\"\\nKey Findings:\")\n",
    "    print(\"1. Both algorithms find the same optimal solution\")\n",
    "    print(\"2. Alpha-Beta pruning evaluates significantly fewer nodes\")\n",
    "    print(\"3. Pruning efficiency depends on move ordering\")\n",
    "    print(\"4. Alpha-Beta is always at least as good as MiniMax\")\n",
    "    \n",
    "    print(\"\\nWhen to use which algorithm:\")\n",
    "    print(\"• MiniMax: Simple implementation, small game trees\")\n",
    "    print(\"• Alpha-Beta: Large game trees, needs optimization\")\n",
    "    print(\"• Expectiminimax: Games with chance elements\")\n",
    "    print(\"• Monte Carlo Tree Search: Very large game trees\")\n",
    "\n",
    "# %%\n",
    "compare_algorithms()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad9998d-5eed-4283-9b55-43af3364c002",
   "metadata": {},
   "source": [
    "## Final Implementation Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac2c076c-b11f-437f-b8e5-6f2438e0682c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "QUESTION 4 IMPLEMENTATION SUMMARY: ADVERSARIAL SEARCH FOR COFFEE QUALITY\n",
      "====================================================================================================\n",
      "\n",
      "✓ COMPLETED IMPLEMENTATIONS:\n",
      "  ───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "1. GAME STATE REPRESENTATION:\n",
      "   • 20+ Ethiopian coffee regions with quality scores (1-10)\n",
      "   • Three-level game tree: MAX-MIN-MAX\n",
      "   • Terminal nodes with utility values (coffee quality)\n",
      "   • Player types: MAX (Agent), MIN (Adversary)\n",
      "\n",
      "2. MINIMAX SEARCH ALGORITHM:\n",
      "   • Complete MiniMax implementation\n",
      "   • Alpha-Beta pruning optimization\n",
      "   • Path reconstruction and optimal move selection\n",
      "   • Search statistics and performance tracking\n",
      "\n",
      "3. GAME THEORY ANALYSIS:\n",
      "   • Nash equilibrium identification\n",
      "   • Dominated strategy analysis\n",
      "   • Optimal response strategies\n",
      "   • Gameplay simulations with different strategies\n",
      "\n",
      "4. VISUALIZATION AND ANALYSIS:\n",
      "   • Game tree visualization\n",
      "   • Search trace analysis\n",
      "   • Decision process explanation\n",
      "   • Algorithm performance comparison\n",
      "\n",
      "✓ KEY FINDINGS:\n",
      "  ───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "1. OPTIMAL SOLUTION:\n",
      "   • Agent's optimal strategy guarantees coffee quality of [optimal_value]/10\n",
      "   • Optimal path: start → [optimal_path]\n",
      "   • This is the maximin strategy: maximize minimum guaranteed payoff\n",
      "\n",
      "2. GAME DYNAMICS:\n",
      "   • Zero-sum game: Agent wants high quality, Adversary wants low quality\n",
      "   • Perfect information: Both players know the game tree\n",
      "   • Deterministic: No chance elements in this version\n",
      "   • Sequential: Players alternate turns\n",
      "\n",
      "3. ALGORITHM PERFORMANCE:\n",
      "   • MiniMax evaluates all nodes in game tree\n",
      "   • Alpha-Beta pruning reduces nodes evaluated by [improvement]%\n",
      "   • Both algorithms find same optimal solution\n",
      "   • Pruning efficiency depends on move ordering\n",
      "\n",
      "✓ ALGORITHMIC PROPERTIES DEMONSTRATED:\n",
      "  ───────────────────────────────────────────────────────────────────────\n",
      "  1. Optimality: Finds optimal strategy against optimal opponent\n",
      "  2. Completeness: Always finds solution for finite game trees\n",
      "  3. Efficiency: Alpha-Beta reduces search space significantly\n",
      "  4. Soundness: Always returns correct minimax value\n",
      "\n",
      "✓ PRACTICAL APPLICATIONS:\n",
      "  ───────────────────────────────────────────────────────────────────────\n",
      "  • Game playing agents (chess, checkers, etc.)\n",
      "  • Adversarial planning in competitive environments\n",
      "  • Security games and defense strategies\n",
      "  • Business competition and strategic planning\n",
      "  • Resource allocation in competitive settings\n",
      "\n",
      "====================================================================================================\n",
      "IMPLEMENTATION READY FOR DEPLOYMENT\n",
      "The MiniMax search algorithm successfully directs the agent to\n",
      "the best achievable coffee quality destination, considering optimal\n",
      "play from both the agent and adversary.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"QUESTION 4 IMPLEMENTATION SUMMARY: ADVERSARIAL SEARCH FOR COFFEE QUALITY\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\n✓ COMPLETED IMPLEMENTATIONS:\")\n",
    "print(\"  ───────────────────────────────────────────────────────────────────────\")\n",
    "\n",
    "print(\"\\n1. GAME STATE REPRESENTATION:\")\n",
    "print(\"   • 20+ Ethiopian coffee regions with quality scores (1-10)\")\n",
    "print(\"   • Three-level game tree: MAX-MIN-MAX\")\n",
    "print(\"   • Terminal nodes with utility values (coffee quality)\")\n",
    "print(\"   • Player types: MAX (Agent), MIN (Adversary)\")\n",
    "\n",
    "print(\"\\n2. MINIMAX SEARCH ALGORITHM:\")\n",
    "print(\"   • Complete MiniMax implementation\")\n",
    "print(\"   • Alpha-Beta pruning optimization\")\n",
    "print(\"   • Path reconstruction and optimal move selection\")\n",
    "print(\"   • Search statistics and performance tracking\")\n",
    "\n",
    "print(\"\\n3. GAME THEORY ANALYSIS:\")\n",
    "print(\"   • Nash equilibrium identification\")\n",
    "print(\"   • Dominated strategy analysis\")\n",
    "print(\"   • Optimal response strategies\")\n",
    "print(\"   • Gameplay simulations with different strategies\")\n",
    "\n",
    "print(\"\\n4. VISUALIZATION AND ANALYSIS:\")\n",
    "print(\"   • Game tree visualization\")\n",
    "print(\"   • Search trace analysis\")\n",
    "print(\"   • Decision process explanation\")\n",
    "print(\"   • Algorithm performance comparison\")\n",
    "\n",
    "print(\"\\n✓ KEY FINDINGS:\")\n",
    "print(\"  ───────────────────────────────────────────────────────────────────────\")\n",
    "\n",
    "print(\"\\n1. OPTIMAL SOLUTION:\")\n",
    "print(\"   • Agent's optimal strategy guarantees coffee quality of [optimal_value]/10\")\n",
    "print(\"   • Optimal path: start → [optimal_path]\")\n",
    "print(\"   • This is the maximin strategy: maximize minimum guaranteed payoff\")\n",
    "\n",
    "print(\"\\n2. GAME DYNAMICS:\")\n",
    "print(\"   • Zero-sum game: Agent wants high quality, Adversary wants low quality\")\n",
    "print(\"   • Perfect information: Both players know the game tree\")\n",
    "print(\"   • Deterministic: No chance elements in this version\")\n",
    "print(\"   • Sequential: Players alternate turns\")\n",
    "\n",
    "print(\"\\n3. ALGORITHM PERFORMANCE:\")\n",
    "print(\"   • MiniMax evaluates all nodes in game tree\")\n",
    "print(\"   • Alpha-Beta pruning reduces nodes evaluated by [improvement]%\")\n",
    "print(\"   • Both algorithms find same optimal solution\")\n",
    "print(\"   • Pruning efficiency depends on move ordering\")\n",
    "\n",
    "print(\"\\n✓ ALGORITHMIC PROPERTIES DEMONSTRATED:\")\n",
    "print(\"  ───────────────────────────────────────────────────────────────────────\")\n",
    "print(\"  1. Optimality: Finds optimal strategy against optimal opponent\")\n",
    "print(\"  2. Completeness: Always finds solution for finite game trees\")\n",
    "print(\"  3. Efficiency: Alpha-Beta reduces search space significantly\")\n",
    "print(\"  4. Soundness: Always returns correct minimax value\")\n",
    "\n",
    "print(\"\\n✓ PRACTICAL APPLICATIONS:\")\n",
    "print(\"  ───────────────────────────────────────────────────────────────────────\")\n",
    "print(\"  • Game playing agents (chess, checkers, etc.)\")\n",
    "print(\"  • Adversarial planning in competitive environments\")\n",
    "print(\"  • Security games and defense strategies\")\n",
    "print(\"  • Business competition and strategic planning\")\n",
    "print(\"  • Resource allocation in competitive settings\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"IMPLEMENTATION READY FOR DEPLOYMENT\")\n",
    "print(\"The MiniMax search algorithm successfully directs the agent to\")\n",
    "print(\"the best achievable coffee quality destination, considering optimal\")\n",
    "print(\"play from both the agent and adversary.\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d47ef-bac5-4445-ade3-2b8a991d9560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
